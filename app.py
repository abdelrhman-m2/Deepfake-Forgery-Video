import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import TimeDistributed, GlobalAveragePooling2D, LSTM, Dense
from tensorflow.keras.optimizers import Adam
import tempfile
import os
from PIL import Image
import plotly.graph_objects as go
import plotly.express as px
import time


# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="DeepFake Detective",
    page_icon="ğŸ•µï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ØªØ®ØµÙŠØµ CSS Ù„Ù„ØªØµÙ…ÙŠÙ…
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    .feature-box {
    background: #f8f9fa;
    padding: 1.5rem;
    border-radius: 10px;
    border-left: 4px solid #667eea;
    margin: 1rem 0;
    box-shadow: 0 4px 16px rgba(0,0,0,0.1);
    color: #000; /* â† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ÙŠØºÙŠÙ‘Ø± Ù„ÙˆÙ† Ø§Ù„Ø®Ø· Ù„Ù„Ø£Ø³ÙˆØ¯ */
    }


    
    .result-box {
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    .real-result {
        background: linear-gradient(135deg, #4CAF50, #45a049);
        color: white;
    }
    
    .fake-result {
        background: linear-gradient(135deg, #f44336, #d32f2f);
        color: white;
    }
    
    .upload-section {
        background: white;
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        border: 2px dashed #667eea;
    }
    
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 16px rgba(0,0,0,0.1);
        text-align: center;
    }
    
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
    
    .stProgress .st-bo {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
</style>
""", unsafe_allow_html=True)

# Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©
IMG_SIZE = 224
SEQ_LENGTH = 10

@st.cache_resource
def load_model():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨"""
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸
        model = tf.keras.models.load_model("deepfake_detector_lstm.h5")
        return model
    except:
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ§Ø­Ø§Ù‹ØŒ Ù‚Ù… Ø¨Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯
        st.warning("âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø³ÙŠØªÙ… Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯.")
        
        base_cnn = MobileNetV2(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))
        base_cnn.trainable = False
        
        model = Sequential([
            TimeDistributed(base_cnn, input_shape=(SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3)),
            TimeDistributed(GlobalAveragePooling2D()),
            LSTM(64, return_sequences=False),
            Dense(64, activation='relu'),
            Dense(2, activation='softmax')
        ])
        
        model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
        return model

def extract_frames(video_path, seq_length=SEQ_LENGTH):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
    cap = cv2.VideoCapture(video_path)
    frames = []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if total_frames == 0:
        return None
    
    frame_idxs = np.linspace(0, total_frames - 1, seq_length).astype(int)
    
    for i in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            break
        if i in frame_idxs:
            frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))
            frame = frame / 255.0
            frames.append(frame)
    
    cap.release()
    
    # Ø¥Ø¶Ø§ÙØ© Ø¥Ø·Ø§Ø±Ø§Øª ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
    while len(frames) < seq_length:
        frames.append(np.zeros((IMG_SIZE, IMG_SIZE, 3)))
    
    return np.array(frames)

def predict_video(video_path, model):
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"""
    frames = extract_frames(video_path)
    
    if frames is None:
        return None, 0
    
    input_array = np.expand_dims(frames, axis=0)
    prediction = model.predict(input_array, verbose=0)
    
    class_idx = np.argmax(prediction)
    confidence = prediction[0][class_idx]
    
    return class_idx, confidence

def create_confidence_chart(confidence, is_real):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ø§Ù„Ø«Ù‚Ø©"""
    labels = ['Real Video', 'Fake Video']
    values = [confidence if is_real else 1-confidence, 1-confidence if is_real else confidence]
    colors = ['#4CAF50', '#f44336']
    
    fig = go.Figure(data=[go.Bar(
        x=labels,
        y=values,
        marker_color=colors,
        text=[f'{v:.1%}' for v in values],
        textposition='auto',
    )])
    
    fig.update_layout(
        title="Confidence Analysis",
        yaxis_title="Confidence Level",
        xaxis_title="Prediction",
        font=dict(size=14),
        height=400,
        showlegend=False
    )
    
    return fig

def main():
    # ØªÙ‡ÙŠØ¦Ø© session state
    if 'analyzed_videos' not in st.session_state:
        st.session_state.analyzed_videos = 0
    
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ•µï¸ DeepFake Detective</h1>
        <p>Advanced AI-Powered Video Authenticity Analyzer</p>
        <p>Detect deepfake videos with cutting-edge machine learning technology</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.markdown("### ğŸ›ï¸ Control Panel")
        st.markdown("---")
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        st.markdown("### ğŸ§  Model Information")
        st.info("""
        **Architecture:** MobileNetV2 + LSTM
        **Input:** Video sequences (10 frames)
        **Output:** Real/Fake classification
        **Confidence:** Probability score
        """)
        
        # Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        st.markdown("### âš™ï¸ Settings")
        show_frames = st.checkbox("Show extracted frames", value=True)
        show_analysis = st.checkbox("Show detailed analysis", value=True)
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        st.markdown("### ğŸ“– How to Use")
        st.markdown("""
        1. **Upload** a video file (MP4, AVI, MOV)
        2. **Wait** for processing to complete
        3. **View** the results and confidence score
        4. **Analyze** the detailed breakdown
        """)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        st.markdown("### ğŸ“Š Session Stats")
        st.metric("Videos Analyzed", st.session_state.analyzed_videos)
    
    # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ“ Upload Video for Analysis")
        st.markdown('<div class="upload-section">', unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "Choose a video file",
            type=['mp4', 'avi', 'mov'],
            help="Upload a video file to analyze for deepfake detection"
        )
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        if uploaded_file is not None:
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù…Ø¤Ù‚ØªØ§Ù‹
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                tmp_file.write(uploaded_file.read())
                video_path = tmp_file.name
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
            st.markdown("### ğŸ“¹ Video Information")
            col_info1, col_info2, col_info3 = st.columns(3)
            
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 0
            cap.release()
            
            with col_info1:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("Duration", f"{duration:.1f}s")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col_info2:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("FPS", f"{fps:.1f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col_info3:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("Frames", frame_count)
                st.markdown('</div>', unsafe_allow_html=True)
            
            # Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
            st.markdown("### ğŸ¬ Original Video")
            st.video(uploaded_file)
            
            # Ø²Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„
            if st.button("ğŸ” Analyze Video", type="primary", use_container_width=True):
                with st.spinner("ğŸ”„ Loading AI model..."):
                    model = load_model()
                
                with st.spinner("ğŸ¯ Analyzing video for deepfake detection..."):
                    progress_bar = st.progress(0)
                    
                    for i in range(100):
                        time.sleep(0.01)
                        progress_bar.progress(i + 1)
                    
                    class_idx, confidence = predict_video(video_path, model)
                    
                    if class_idx is not None:
                        st.session_state.analyzed_videos += 1
                        
                        is_real = class_idx == 0
                        label = "REAL" if is_real else "FAKE"
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                        st.markdown("### ğŸ¯ Analysis Results")
                        
                        result_class = "real-result" if is_real else "fake-result"
                        icon = "âœ…" if is_real else "âŒ"
                        
                        st.markdown(f"""
                        <div class="result-box {result_class}">
                            <h2>{icon} {label}</h2>
                            <h3>Confidence: {confidence:.1%}</h3>
                            <p>{'This video appears to be authentic' if is_real else 'This video appears to be deepfake/manipulated'}</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Ù…Ø®Ø·Ø· Ø§Ù„Ø«Ù‚Ø©
                        if show_analysis:
                            st.markdown("### ğŸ“Š Confidence Analysis")
                            fig = create_confidence_chart(confidence, is_real)
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
                        if show_frames:
                            st.markdown("### ğŸ–¼ï¸ Extracted Frames for Analysis")
                            frames = extract_frames(video_path)
                            
                            if frames is not None:
                                cols = st.columns(5)
                                for i, frame in enumerate(frames[:10]):
                                    if i < len(cols):
                                        with cols[i % 5]:
                                            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ù„Ù„Ø¹Ø±Ø¶
                                            frame_display = (frame * 255).astype(np.uint8)
                                            st.image(frame_display, caption=f"Frame {i+1}", use_column_width=True)
                                    
                                    if i == 4:
                                        cols = st.columns(5)
                    else:
                        st.error("âŒ Error processing video. Please try a different file.")
                
                # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                os.unlink(video_path)
    
    with col2:
        st.markdown("### ğŸ¯ Detection Features")
        
        features = [
            ("ğŸ§ ", "Deep Learning", "Advanced neural network architecture"),
            ("ğŸ“±", "Mobile Optimized", "Efficient MobileNetV2 backbone"),
            ("ğŸ¬", "Video Analysis", "Sequential frame processing"),
            ("âš¡", "Fast Processing", "Quick and accurate detection"),
            ("ğŸ”", "High Accuracy", "Trained on extensive datasets"),
            ("ğŸ“Š", "Confidence Score", "Probability-based results")
        ]
        
        for icon, title, desc in features:
            st.markdown(f"""
            <div class="feature-box">
                <h4>{icon} {title}</h4>
                <p>{desc}</p>
            </div>
            """, unsafe_allow_html=True)
        
        # ØªØ­Ø°ÙŠØ±Ø§Øª Ù…Ù‡Ù…Ø©
        st.markdown("### âš ï¸ Important Notes")
        st.warning("""
        - This tool is for educational purposes
        - Results may vary based on video quality
        - Always verify results with multiple sources
        - Not 100% accurate - use with caution
        """)
    
    # ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666;">
        <p>ğŸ”¬ Powered by TensorFlow & Streamlit | ğŸš€ Built with Advanced AI Technology</p>
        <p>âš¡ For research and educational purposes only</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
